{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9facbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d26818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0333033b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29b54dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#character encoding\n",
    "\n",
    "chars = sorted(list(set(''.join(words)))) \n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}  #maps characters to integers\n",
    "stoi['.'] = 0                               # . = 0, a = 1, b = 2, ..., z = 26\n",
    "itos = {i:s for s,i in stoi.items()}        #remaps integers to characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2909bc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# let's create the training set of bigrams (x,y)\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    #print(ch1, ch2)\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "    \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87e06ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  5, 13,  ..., 25, 26, 24]),\n",
       " tensor([ 5, 13, 13,  ..., 26, 24,  0]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28d1970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converts the integers to a 27-dimensional vector using one-hot encoding\n",
    "\n",
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5465eef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 27])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c008b1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6235, -1.5779, -0.4353,  ...,  0.4561, -0.3079,  0.5908],\n",
       "        [-0.7750,  0.8377,  1.9633,  ...,  1.3582, -0.2448, -1.0104],\n",
       "        [ 0.0557,  2.0179,  0.1426,  ..., -0.3167,  1.1315,  1.6629],\n",
       "        ...,\n",
       "        [-1.0436,  1.3638,  0.9527,  ..., -1.5812,  0.6337, -0.2417],\n",
       "        [-1.0589,  0.1361, -0.8992,  ..., -1.7689,  1.1836, -0.7171],\n",
       "        [-0.1194,  1.0546,  0.0868,  ..., -1.9429, -1.7843,  0.1652]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn((27, 27), requires_grad = True) #generates a random set of weights based on normal \n",
    "logits = xenc @ W         #using matrix multiplication to perform (x*w) \n",
    "logits                    #weighted sum of one-hot encoded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54196776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0173, 0.0067, 0.0209,  ..., 0.0510, 0.0238, 0.0584],\n",
       "        [0.0080, 0.0403, 0.1241,  ..., 0.0678, 0.0136, 0.0063],\n",
       "        [0.0231, 0.1645, 0.0252,  ..., 0.0159, 0.0678, 0.1154],\n",
       "        ...,\n",
       "        [0.0056, 0.0618, 0.0410,  ..., 0.0033, 0.0298, 0.0124],\n",
       "        [0.0093, 0.0306, 0.0109,  ..., 0.0046, 0.0872, 0.0130],\n",
       "        [0.0203, 0.0657, 0.0250,  ..., 0.0033, 0.0038, 0.0270]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#softmax implementation\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29a7b9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7106027603149414\n",
      "3.37222957611084\n",
      "3.156460762023926\n",
      "3.0200746059417725\n",
      "2.9315707683563232\n",
      "2.867912530899048\n",
      "2.819028377532959\n",
      "2.77999210357666\n",
      "2.747936248779297\n",
      "2.7210605144500732\n",
      "2.6981966495513916\n",
      "2.6785390377044678\n",
      "2.6615073680877686\n",
      "2.6466641426086426\n",
      "2.633666753768921\n",
      "2.6222383975982666\n",
      "2.6121466159820557\n",
      "2.603194236755371\n",
      "2.59521484375\n",
      "2.5880656242370605\n",
      "2.5816283226013184\n",
      "2.575803279876709\n",
      "2.570507526397705\n",
      "2.565673351287842\n",
      "2.561244249343872\n",
      "2.5571727752685547\n",
      "2.5534188747406006\n",
      "2.5499484539031982\n",
      "2.5467326641082764\n",
      "2.5437464714050293\n",
      "2.540968656539917\n",
      "2.5383784770965576\n",
      "2.5359609127044678\n",
      "2.5336992740631104\n",
      "2.5315802097320557\n",
      "2.5295932292938232\n",
      "2.5277259349823\n",
      "2.5259697437286377\n",
      "2.524315595626831\n",
      "2.5227551460266113\n",
      "2.5212819576263428\n",
      "2.5198893547058105\n",
      "2.5185706615448\n",
      "2.5173213481903076\n",
      "2.516136407852173\n",
      "2.5150113105773926\n",
      "2.5139412879943848\n",
      "2.512923240661621\n",
      "2.511953592300415\n",
      "2.511029005050659\n",
      "2.5101468563079834\n",
      "2.5093040466308594\n",
      "2.508498191833496\n",
      "2.50772762298584\n",
      "2.5069897174835205\n",
      "2.506282329559326\n",
      "2.505603790283203\n",
      "2.5049524307250977\n",
      "2.5043272972106934\n",
      "2.503726005554199\n",
      "2.503148078918457\n",
      "2.502591848373413\n",
      "2.502056121826172\n",
      "2.501540422439575\n",
      "2.501042604446411\n",
      "2.500562906265259\n",
      "2.5001001358032227\n",
      "2.499652624130249\n",
      "2.499220609664917\n",
      "2.4988036155700684\n",
      "2.4983999729156494\n",
      "2.49800968170166\n",
      "2.497631788253784\n",
      "2.4972660541534424\n",
      "2.4969122409820557\n",
      "2.4965689182281494\n",
      "2.496236562728882\n",
      "2.4959137439727783\n",
      "2.495601177215576\n",
      "2.495297908782959\n",
      "2.4950034618377686\n",
      "2.494717597961426\n",
      "2.4944398403167725\n",
      "2.4941704273223877\n",
      "2.493908405303955\n",
      "2.4936535358428955\n",
      "2.493406057357788\n",
      "2.4931654930114746\n",
      "2.4929311275482178\n",
      "2.492703437805176\n",
      "2.4924814701080322\n",
      "2.492265462875366\n",
      "2.4920551776885986\n",
      "2.4918503761291504\n",
      "2.4916510581970215\n",
      "2.4914565086364746\n",
      "2.491267204284668\n",
      "2.4910824298858643\n",
      "2.4909021854400635\n",
      "2.4907267093658447\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(100):\n",
    "  \n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "  logits = xenc @ W # predict log-counts\n",
    "    \n",
    "  #softmax implementation\n",
    "  counts = logits.exp() \n",
    "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "\n",
    "  #negative log likelihood loss + L2 regularization\n",
    "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
    "  print(loss.item())\n",
    "  \n",
    "  # backward pass\n",
    "  W.grad = None # set to zero the gradient\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a22b7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lee.\n",
      "autinaushan.\n",
      "n.\n",
      "be.\n",
      "ahara.\n",
      "alona.\n",
      "arillain.\n",
      "ha.\n",
      "chiursh.\n",
      "li.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(345678987654)\n",
    "\n",
    "for i in range(10):\n",
    "  \n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    \n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
